###################################################################################
Preparation:
1. strat hdfs
$~/hadoop-2.2.0/sbin/start-hdfs.sh

2. start yarn
$~/hadoop-2.2.0/sbin/start-yarn.sh

you can type the command: jps to check whether the service is running
$jps

3. prepare the test data and mkdir in hdfs
$HADOOP_HOME/bin/hadoop fs -mkdir /testdata
$HADOOP_HOME/bin/hadoop fs -put <local path to synthetic_control.data> /testdata

4. modify the $MAHOUT_HOME/bin/mahout
modify the $JAVA_HOME, $HADOOP_HOME, $HADOOP_BINARY, $HADOOP_CONF_DIR
bin/mahout is attached.

5. generate the mahout-examples-*-*-job.jar in mahout-src
$mvn clean install -DskipTests=true
if build successfully, you'll find the following jar:
MAHOUT_HOME/examples/target/mahout-examples-0.9-SNAPSHOT-job.jar

###################################################################################
Perform Clustering experiments:
1. Canopy
2. Kmeans
3. Fuzzykmeans
4. Dirichlet (removed in mahout-0.9)
5. Meanshift (not found in mahout-0.9)

note:
================================================================
Valid program names are:
  arff.vector: : Generate Vectors from an ARFF file or directory
  baumwelch: : Baum-Welch algorithm for unsupervised HMM training
  canopy: : Canopy clustering
  cat: : Print a file or resource as the logistic regression models would see it
  cleansvd: : Cleanup and verification of SVD output
  clusterdump: : Dump cluster output to text
  clusterpp: : Groups Clustering Output In Clusters
  cmdump: : Dump confusion matrix in HTML or text formats
  concatmatrices: : Concatenates 2 matrices of same cardinality into a single matrix
  cvb: : LDA via Collapsed Variation Bayes (0th deriv. approx)
  cvb0_local: : LDA via Collapsed Variation Bayes, in memory locally.
  evaluateFactorization: : compute RMSE and MAE of a rating matrix factorization against probes
  fkmeans: : Fuzzy K-means clustering
  hmmpredict: : Generate random sequence of observations by given HMM
  itemsimilarity: : Compute the item-item-similarities for item-based collaborative filtering
  kmeans: : K-means clustering
  lucene.vector: : Generate Vectors from a Lucene index
  lucene2seq: : Generate Text SequenceFiles from a Lucene index
  matrixdump: : Dump matrix in CSV format
  matrixmult: : Take the product of two matrices
  parallelALS: : ALS-WR factorization of a rating matrix
  qualcluster: : Runs clustering experiments and summarizes results in a CSV
  recommendfactorized: : Compute recommendations using the factorization of a rating matrix
  recommenditembased: : Compute recommendations using item-based collaborative filtering
  regexconverter: : Convert text files on a per line basis based on regular expressions
  resplit: : Splits a set of SequenceFiles into a number of equal splits
  rowid: : Map SequenceFile<Text,VectorWritable> to {SequenceFile<IntWritable,VectorWritable>, SequenceFile<IntWritable,Text>}
  rowsimilarity: : Compute the pairwise similarities of the rows of a matrix
  runAdaptiveLogistic: : Score new production data using a probably trained and validated AdaptivelogisticRegression model
  runlogistic: : Run a logistic regression model against CSV data
  seq2encoded: : Encoded Sparse Vector generation from Text sequence files
  seq2sparse: : Sparse Vector generation from Text sequence files
  seqdirectory: : Generate sequence files (of Text) from a directory
  seqdumper: : Generic Sequence File dumper
  seqmailarchives: : Creates SequenceFile from a directory containing gzipped mail archives
  seqwiki: : Wikipedia xml dump to sequence file
  spectralkmeans: : Spectral k-means clustering
  split: : Split Input data into test and train sets
  splitDataset: : split a rating dataset into training and probe parts
  ssvd: : Stochastic SVD
  streamingkmeans: : Streaming k-means clustering
  svd: : Lanczos Singular Value Decomposition
  testnb: : Test the Vector-based Bayes classifier
  trainAdaptiveLogistic: : Train an AdaptivelogisticRegression model
  trainlogistic: : Train a logistic regression using stochastic gradient descent
  trainnb: : Train the Vector-based Bayes classifier
  transpose: : Take the transpose of a matrix
  validateAdaptiveLogistic: : Validate an AdaptivelogisticRegression model against hold-out data set
  vecdist: : Compute the distances between a set of Vectors (or Cluster or Canopy, they must fit in memory) and a list of Vectors
  vectordump: : Dump vectors from a sequence file to text
  viterbi: : Viterbi decoding of hidden states from given output states sequence
================================================================


###################################################################################
Canopy:
================================================================
usage:
bin/mahout canopy \
    -i <input vectors directory> \
    -o <output working directory> \
    -dm <DistanceMeasure> \
    -t1 <T1 threshold> \
    -t2 <T2 threshold> \
    -t3 <optional reducer T1 threshold> \
    -t4 <optional reducer T2 threshold> \
    -cf <optional cluster filter size (default: 0)> \
    -ow <overwrite output directory if present>
    -cl <run input vector clustering after computing Canopies>
    -xm <execution method: sequential or mapreduce>
================================================================

1. execute the canopy job:
$MAHOUT_HOME/bin/mahout org.apache.mahout.clustering.syntheticcontrol.canopy.Job 
  -i /testdata -o /testresult --t1 0.1 --t2 0.2

2. format the result for human readable:
$MAHOUT_HOME/bin/mahout seqdumper -i /testresult/clusteredPoints/part-m-00000 
  -o {local path}/canopy_result.txt

###################################################################################
Kmeans:
================================================================
bin/mahout kmeans \
    -i <input vectors directory> \
    -c <input clusters directory> \
    -o <output working directory> \
    -k <optional number of initial clusters to sample from input vectors> \
    -dm <DistanceMeasure> \
    -x <maximum number of iterations> \
    -cd <optional convergence delta. Default is 0.5> \
    -ow <overwrite output directory if present>
    -cl <run input vector clustering after computing Canopies>
    -xm <execution method: sequential or mapreduce>
================================================================

1. execute the kmeans job:
$MAHOUT_HOME/bin/mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job
  -i /testdata -o /kmeans_result -t1 0.1 -t2 0.2 --maxIter 100

2. format the result for human readable:
$MAHOUT_HOME/bin/mahout seqdumper -i /kmeans_result/clusteredPoints/part-m-00000
  -o {local path}/kmeans_result.txt

###################################################################################
FuzzyKmeans:
================================================================
Usage:
 [--input <input> --output <output> --distanceMeasure <distanceMeasure>
--convergenceDelta <convergenceDelta> --maxIter <maxIter> --overwrite --t1 <t1>
--t2 <t2> --m <m> --help --tempDir <tempDir> --startPhase <startPhase>
--endPhase <endPhase>]
--maxIter (-x) maxIter    The maximum number of iterations.
================================================================

1. execute the fuzzy k-means job:
$MAHOUT_HOME/bin/mahout org.apache.mahout.clustering.syntheticcontrol.fuzzykmeans.Job 
  -i /testdata -o /fuzzykmeans_result --t1 0.1 --t2 0.2 --maxIter 100 --m 2

2. format the result for human readable:
$MAHOUT_HOME/bin/mahout seqdumper 
-i /fuzzykmeans_result/clusteredPoints/part-m-00000 -o /root/fuzzykmeans_result.txt

###################################################################################
Reference:
1. https://cwiki.apache.org/confluence/display/MAHOUT/Clustering+of+synthetic+control+data
2. http://blog.sina.com.cn/s/blog_4aa9c9d10101lid4.html 

Canopy:
1. https://cwiki.apache.org/confluence/display/MAHOUT/Canopy+Clustering

K-means:
1. https://cwiki.apache.org/confluence/display/MAHOUT/K-Means+Clustering

Fuzzy K-means:
1. https://cwiki.apache.org/confluence/display/MAHOUT/Fuzzy+K-Means

Dirichlet:
1. https://cwiki.apache.org/confluence/display/MAHOUT/Dirichlet+Process+Clustering

Meanshift:
1. https://cwiki.apache.org/confluence/display/MAHOUT/Mean+Shift+Clustering

Synthetic Control Chart Time Series
1. http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data.html
2. http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data

###################################################################################
