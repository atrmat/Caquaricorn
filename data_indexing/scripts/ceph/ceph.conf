[global]
#auth supported = cephx
auth cluster required = cephx
auth service required = cephx
auth client required = cephx
max open files =131072
#auth supported = none
keyring = /etc/ceph/keyring.admin
public network = 192.168.1.0/24
cluster network = 192.168.1.0/24
osd pool default size = 3
osd pool default min size = 2
[mds]
mds data = /var/lib/ceph/mds/$cluster-$id
keyring = /etc/ceph/keyring.$name
public network = 192.168.1.0/24
cluster network = 192.168.1.0/24
# debug mds = 20
# debug paxos = 20
# debug auth = 20
# debug mds_migrator = 20
# debug monc = 20
[mds.1]
host = ceph01
#public addr = 10.239.149.9
#cluster addr = 192.168.4.100
[osd]
osd data = /var/lib/ceph/osd/$cluster-$id
#osd journal = /var/lib/ceph/osd/$cluster-$id/journal
osd journal size = 10240
osd class dir = /usr/lib/rados-classes
#osd class dir = $(libdir)/rados-classes
keyring = /etc/ceph/keyring.$name
#debug osd = 20
#debug filestore = 20
#debug journal = 20
#debug monc = 20
osd mkfs type = xfs
osd mount options xfs = rw,noatime,nodiratime
osd mkfs options xfs = -f
# working with ext4
#filestore xattr use omap = true
filestore min sync interval = 1.0
# solve rbd data corruption
filestore fiemap = true
public network = 192.168.1.0/24
cluster network = 192.168.1.0/24
[osd.0]
host = ceph01
public addr = 192.168.1.30
cluster addr = 192.168.1.30
devs = /dev/sdb1
[osd.1]
host = ceph01
public addr = 192.168.1.30
cluster addr = 192.168.1.30
devs = /dev/sdb2
[mon]
mon data = /var/lib/ceph/mon/$cluster-$id
# debug ms = 1
# debug mon = 20
# debug paxos = 20
# debug auth = 20
[mon.a]
host = ceph01
mon addr = 192.168.1.30:6789
[client]
#debug ms = 1
#debug client = 10 #20
rbd cache = true
rbd cache writethrough until flush = true

